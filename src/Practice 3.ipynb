{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aef7667-8bf7-4e80-9ba9-4c2273c20500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Roaming\\Python\\Python39\\site-packages\\networkx\\utils\\backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "D:\\anaconda\\envs\\Leaves_Classification\\lib\\site-packages\\albumentations\\check_version.py:147: UserWarning: Error fetching version info <urlopen error TLS/SSL connection has been closed (EOF) (_ssl.c:1147)>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import albumentations\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from PIL import Image\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec8e991-2c2d-4308-a1f4-9abc1f739f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型保存目录\n",
    "os.makedirs('../models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4c4b76-e2c8-4295-b6e2-a9eb09dcdf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练和测试数据\n",
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')\n",
    "# 对标签列进行数字编码\n",
    "train['number'], labels_unique = pd.factorize(train['label'])\n",
    "# # 保存编码结果\n",
    "# train.to_csv('../dataset/train_add_number.csv', index=False)\n",
    "# # 保存标签映射关系\n",
    "# pd.Series(labels_unique).to_csv('../dataset/label_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3e964f-751f-4eaa-bede-f54d5c31878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "transforms_train = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(320, 320),            # 调整图像尺寸到320x320\n",
    "        albumentations.HorizontalFlip(p=0.5),       # 概率50%水平翻转\n",
    "        albumentations.VerticalFlip(p=0.5),         # 概率50%垂直翻转\n",
    "        albumentations.Rotate(limit=180, p=0.7),    # 随机翻转(±180°，概率70%)\n",
    "        albumentations.RandomBrightnessContrast(),  # 随机调整亮度和对比度\n",
    "        albumentations.Affine(\n",
    "            translate_percent = (-0.25, 0.25),  # 平移范围±25%\n",
    "            scale = (0.9, 1.1),                 # 缩放范围±10%\n",
    "            rotate = 0,                         # 无旋转\n",
    "            p = 0.5\n",
    "        ),\n",
    "        albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
    "        ToTensorV2(p=1.0)  # 将图像从 numpy 数组转换为 PyTorch 张量\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 不添加随机增强，确保评估结果的一致性\n",
    "transforms_test = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(320, 320),\n",
    "        albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0baccb3d-b158-4a12-9f71-f1cf76b7406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf_Dataset(Dataset):\n",
    "    def __init__(self, train_csv, transform=None, test_bool=False):\n",
    "        '''\n",
    "        train_csv: 记录图像路径及标号的csv文件\n",
    "        transform: 图像变换\n",
    "        test_bool: 是否为测试集\n",
    "        '''\n",
    "        self.train_csv = train_csv\n",
    "        self.transform = transform\n",
    "        self.test_bool = test_bool\n",
    "        self.image_path = list(self.train_csv['image'])  # 提取所有图像路径\n",
    "        # 如果不是测试集，加载标签信息\n",
    "        if not test_bool:\n",
    "            self.label_nums = list(self.train_csv['number'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        获取单个样本\n",
    "        idx：样本索引\n",
    "        return: image, label\n",
    "        '''\n",
    "        # 读取图像\n",
    "        image = cv2.imread(os.path.join('../dataset', self.image_path[idx]))\n",
    "        # 转换颜色空间\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # 图像变换\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        # 测试集只返回图像，训练集和验证集返回图像和标签\n",
    "        if not self.test_bool:\n",
    "            label = self.label_nums[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e07c85e-cb54-43f9-819a-9764583ddc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, valid_loader, test, fold_n, device=torch.device('cuda:0')):\n",
    "    # 模型初始化\n",
    "    net = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    in_features = net.fc.in_features      # 获取全连接层的输入特征维度\n",
    "    net.fc = nn.Linear(in_features, 176)  # 替换全连接层以适应176类树叶分类任务\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 训练参数设置\n",
    "    epoch = 30\n",
    "    best_epoch = 0\n",
    "    best_score = 0.0\n",
    "    best_model_state = None   # 保存最佳模型状态\n",
    "    early_stopping_round = 3  # 早停轮数\n",
    "    losses = []               # 记录每轮的训练损失\n",
    "\n",
    "    # 优化器、损失函数和调度器\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    # 训练循环\n",
    "    for i in range(epoch):\n",
    "        acc = 0       # 累计训练准确数\n",
    "        loss_sum = 0  # 累计训练损失\n",
    "\n",
    "        # 训练阶段\n",
    "        net.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            # 准备输入数据\n",
    "            x = torch.as_tensor(x, dtype=torch.float).to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(x)\n",
    "\n",
    "            # 计算损失\n",
    "            loss_temp = loss(y_hat, y)\n",
    "            loss_sum += loss_temp\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss_temp.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 计算准确数\n",
    "            acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "        # 记录平均损失\n",
    "        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n",
    "\n",
    "        # 打印训练结果\n",
    "        print('epoch: ', i,\n",
    "             'loss: ', loss_sum.item(),\n",
    "             'train acc: ', (acc / (len(train_loader) * train_loader.batch_size)).item(), end='')\n",
    "\n",
    "        # 验证阶段\n",
    "        valid_acc = 0.0\n",
    "        net.eval()\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            # 准备输入数据\n",
    "            x = torch.as_tensor(x, dtype=torch.float).to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            with torch.no_grad():\n",
    "                y_hat = net(x)\n",
    "\n",
    "            # 计算准确数\n",
    "            valid_acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n",
    "\n",
    "        # 计算并打印验证准确率\n",
    "        print('valid acc: ', (valid_acc / (len(valid_loader) * valid_loader.batch_size)).item())\n",
    "\n",
    "        # 模型保存与早停\n",
    "        if valid_acc > best_score:\n",
    "            best_model_state = copy.deepcopy(net.state_dict())\n",
    "            best_score = valid_acc\n",
    "            best_epoch = i\n",
    "            print('best epoch save!')\n",
    "\n",
    "        if i - best_epoch >= early_stopping_round:\n",
    "            print(f'Early stopping at epoch {i}')\n",
    "            break\n",
    "\n",
    "    # 保存最佳模型\n",
    "    model_path = f'../models/fold_{fold_n}_best_model.pth'\n",
    "    torch.save({'model_state_dict': best_model_state}, model_path)\n",
    "    print(f'Saved model for fold {fold_n} at {model_path}')\n",
    "\n",
    "    # 加载最佳模型\n",
    "    net.load_state_dict(best_model_state)\n",
    "\n",
    "    # 加载测试数据\n",
    "    testset = Leaf_Dataset(test, transform=transforms_test, test_bool=True)\n",
    "    test_loader = DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "    # 执行预测\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            # 准备输入数据\n",
    "            x = torch.as_tensor(x, dtype=torch.float).to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = net(x)\n",
    "\n",
    "            # 获取预测结果\n",
    "            predict = torch.argmax(y_hat, dim=1).reshape(-1)\n",
    "            predict = list(predict.cpu().detach().numpy())\n",
    "            predictions.extend(predict)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c472688-d72a-4c18-a82b-1069e3c2b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化分层K折交叉验证器\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n",
    "\n",
    "# 创建空 DataFrame 存储各折的预测结果\n",
    "prediction_KFold = pd.DataFrame()\n",
    "\n",
    "# 开始K折交叉验证\n",
    "for fold_n, (train_idx, val_idx) in enumerate(skf.split(train, train['number'])):\n",
    "    print(f'fold {fold_n} training...')\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_data = train.iloc[train_idx]\n",
    "    valid_data = train.iloc[val_idx]\n",
    "\n",
    "    # 创建数据集对象\n",
    "    trainset = Leaf_Dataset(train_data, transform=transforms_train)\n",
    "    validset = Leaf_Dataset(valid_data, transform=transforms_test)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(trainset, batch_size=32, shuffle=True, drop_last=False)\n",
    "    valid_loader = DataLoader(validset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "    # 训练模型并在测试集上预测\n",
    "    predictions = train_model(train_loader, valid_loader, test, fold_n)\n",
    "\n",
    "    # 存储当前折的预测结果\n",
    "    prediction_KFold[f'fold {fold_n}'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb7fa5-85b1-445c-b12c-2b16acb41d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看各折预测结果\n",
    "print(prediction_KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83918a08-5e6c-42bb-bb21-709f10ad4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终预测结果采取众数投票\n",
    "prediction_final = list(prediction_KFold.mode(axis=1)[0].astype(int))\n",
    "\n",
    "# 数字标签转换回文本标签\n",
    "test['label'] = [labels_unique[i] for i in prediction_final]\n",
    "\n",
    "# 保存结果文件\n",
    "test.to_csv('../dataset/result_practice3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
